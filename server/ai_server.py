import json
import time
import atexit
from collections import deque
from typing import Optional, Dict, Any, List

import numpy as np
import torch
# â˜…â˜…â˜… [ìˆ˜ì • 1] request, jsonify ì¶”ê°€
from flask import Flask, request, jsonify
from flask_sock import Sock
from simple_websocket.errors import ConnectionClosed

# --- ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ ì„í¬íŠ¸ ---
from input_keypoint.advanced_validators import AdvancedHandValidator
from realtime.segmenter import OnlineSegmenter
from realtime.inference_logger import InferenceLogger
from realtime.inference_utils import (
    load_model_and_vocab,
    predict,
    normalize_keypoints_by_bodypart
)
from utils.logger import get_logger
from utils.config import load_config, get_default_config_path
from utils.performance import performance_optimizer

# =============================================================================
# [SETUP] ë¡œê±° ë° ì„¤ì • ì´ˆê¸°í™”
# =============================================================================
logger = get_logger("kslt.server")

config_path = get_default_config_path()
config = load_config(config_path)

# =============================================================================
# [CONSTANTS] ìƒìˆ˜ ì •ì˜
# =============================================================================
KEYPOINT_SLICES = {
    'body': slice(0, 25),
    'face': slice(25, 95),
    'left_hand': slice(95, 116),
    'right_hand': slice(116, 137)
}
NOSE_INDEX = 0
INFERENCE_STRIDE = 5 

# =============================================================================
# [FUNCTIONS] í•µì‹¬ ë¡œì§
# =============================================================================

def preprocess_frame(keypoints_data: List[List[float]]) -> Optional[np.ndarray]:
    """
    í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„°ë¥¼ ëª¨ë¸ ì…ë ¥ìš© 1D ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if not keypoints_data:
        return None

    try:
        keypoints_arr = np.array(keypoints_data, dtype=np.float32)
        
        # ë°ì´í„° í˜•ìƒ ë§ì¶”ê¸° (x, y) -> (x, y, 0) ì²˜ë¦¬ ë“±
        if keypoints_arr.shape[1] == 2:
             zeros = np.zeros((keypoints_arr.shape[0], 1), dtype=np.float32)
             keypoints_arr = np.hstack([keypoints_arr, zeros])

        normalized_keypoints = normalize_keypoints_by_bodypart(
            keypoints_arr, width=1.0, height=1.0
        )

        body_pts = normalized_keypoints[KEYPOINT_SLICES['body']]
        face_pts = normalized_keypoints[KEYPOINT_SLICES['face']]
        lh_pts = normalized_keypoints[KEYPOINT_SLICES['left_hand']]
        rh_pts = normalized_keypoints[KEYPOINT_SLICES['right_hand']]

        nose_pt = body_pts[NOSE_INDEX]
        if nose_pt[2] > 0.1 and not np.isnan(nose_pt[0]):
            body_pts[:, :2] -= nose_pt[:2]

        xy = np.concatenate([
            body_pts[:, :2],
            face_pts[:, :2],
            lh_pts[:, :2],
            rh_pts[:, :2]
        ], axis=0)

        presence_mask_list = []
        for part_name in ['body', 'face', 'left_hand', 'right_hand']:
            part_data = xy[KEYPOINT_SLICES[part_name]]
            has_part = not np.all(np.isnan(part_data))
            length = KEYPOINT_SLICES[part_name].stop - KEYPOINT_SLICES[part_name].start
            presence_mask_list.append(np.full((length, 1), 1.0 if has_part else 0.0))

        presence_mask = np.vstack(presence_mask_list).astype(np.float32)
        coord_mask = (~np.isnan(xy).any(axis=1)).astype(np.float32).reshape(-1, 1)
        mask = presence_mask * coord_mask

        xy = np.nan_to_num(xy, nan=0.0, posinf=0.0, neginf=0.0)
        xy *= mask

        return xy.reshape(-1)
    
    except Exception as e:
        logger.error(f"ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def execute_inference(
    frame_buffer: deque,
    service: Any,
    validator: AdvancedHandValidator,
    session_id: str = "unknown",
    top_k: int = 3,
    required_frames: int = 128
) -> Optional[Dict[str, Any]]:
    """
    ë²„í¼ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    # HTTP ìš”ì²­ ëŒ€ì‘: ë²„í¼ê°€ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ë³µì œí•´ì„œë¼ë„ ì±„ì›€ (Padding)
    buffer_len = len(frame_buffer)
    if buffer_len == 0:
        return None
        
    working_buffer = list(frame_buffer)
    if buffer_len < required_frames:
        # logger.debug(f"[{session_id}] ë²„í¼ ë¶€ì¡±({buffer_len}/{required_frames}). íŒ¨ë”© ìˆ˜í–‰.")
        while len(working_buffer) < required_frames:
            working_buffer.append(working_buffer[-1])

    try:
        start_time = time.perf_counter()
        # required_frames ê°œìˆ˜ë§Œí¼ë§Œ ì˜ë¼ì„œ ì‚¬ìš©
        input_tensor = np.stack(working_buffer[:required_frames], axis=0)

        # 1. ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ (ìƒëµ ê°€ëŠ¥í•˜ì§€ë§Œ ìœ ì§€)
        # keypoints_for_val = input_tensor.reshape(required_frames, 137, 2)
        # val_res = validator.validate_sequence(keypoints_for_val, skip_head_occlusion=True)

        # 2. ëª¨ë¸ ì¶”ë¡ 
        result = service.predict(input_tensor, return_probabilities=True, top_k=top_k)
        elapsed = (time.perf_counter() - start_time) * 1000

        prediction = result['top_prediction']
        confidence = float(result['top_confidence'])

        log_msg = f"[{session_id}] HTTP ì˜ˆì¸¡: '{prediction}' ({confidence:.1f}%) - {elapsed:.1f}ms"
        logger.info(log_msg)

        return {
            "departureCity": prediction,
            "arrivalCity": None, # ë„ì°©ì§€ëŠ” í˜„ì¬ ì¸ì‹ ì•ˆ í•¨
            "recognizedProb": confidence
        }

    except Exception as e:
        logger.error(f"[{session_id}] ì¶”ë¡  ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return {"type": "ERROR", "message": str(e)}


# =============================================================================
# [SERVER INIT] Flask ë° ëª¨ë¸ ë¡œë“œ
# =============================================================================
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False
sock = Sock(app)

MODEL_PATH = "deployment/20251109-1439_Attention/20251109-1439.onnx"
VOCAB_PATH = "deployment/20251109-1439_Attention/vocabulary.txt"
MODEL_TYPE = "onnx"

logger.info("ğŸš€ ì„œë²„ ì‹œì‘: ëª¨ë¸ ë° ë¦¬ì†ŒìŠ¤ ë¡œë”© ì¤‘...")

try:
    SERVICE, VOCAB, DEVICE = load_model_and_vocab(MODEL_PATH, VOCAB_PATH, "auto", MODEL_TYPE)
    realtime_config = config.get_realtime_config()
    logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ (Device: {DEVICE}, Type: {MODEL_TYPE})")
except Exception as e:
    logger.critical(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ì„œë²„ë¥¼ ì¢…ë£Œí•´ì•¼ í•©ë‹ˆë‹¤. {e}", exc_info=True)
    SERVICE, VOCAB, DEVICE = None, None, None

MAX_BUFFER_FRAMES = realtime_config.get('window_size', 200) if MODEL_TYPE == "pytorch" else 128
logger.info(f"âš™ï¸ ì„¤ì • ì™„ë£Œ: Window Size={MAX_BUFFER_FRAMES}, Stride={INFERENCE_STRIDE}")

validator_config = realtime_config.get('validator', {})
GLOBAL_VALIDATOR = AdvancedHandValidator(
    head_occlusion_threshold=validator_config.get('head_occlusion_threshold', 0.8),
    min_hand_movement=validator_config.get('min_hand_movement', 0.01),
    max_frame_gap=validator_config.get('max_frame_gap', 10),
    min_valid_frames_ratio=validator_config.get('min_valid_frames_ratio', 0.3)
)

# =============================================================================
# [ROUTE] HTTP POST (ìë°” ë°±ì—”ë“œ ì—°ë™ìš©) - â˜…â˜…â˜… ìƒˆë¡œ ì¶”ê°€ëœ ë¶€ë¶„ â˜…â˜…â˜…
# =============================================================================
@app.route('/predict_keypoints', methods=['POST'])
def http_predict_keypoints():
    """
    ìë°” ë°±ì—”ë“œì—ì„œ ì˜¤ëŠ” ë°ì´í„°ë¥¼ êµ¬ì¡°ì— ë§ê²Œ ë³€í™˜í•˜ì—¬ ì¶”ë¡ í•©ë‹ˆë‹¤.
    """
    try:
        data = request.get_json()
        session_id = "HTTP_REQ"
        
        keypoint_input = data.get('keypointData') 

        if not keypoint_input:
            return jsonify({"error": "No keypoint data provided"}), 400

        final_keypoints = []

        # â˜…â˜…â˜… [í•µì‹¬ ìˆ˜ì •] ìë°”ê°€ ë³´ë‚´ëŠ” { "keypoints": [...] } êµ¬ì¡° ì²˜ë¦¬
        if isinstance(keypoint_input, dict):
            # 1. 'keypoints'ë¼ëŠ” í‚¤ê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸ (ì´ê²Œ ìš°ë¦¬ê°€ ìˆ˜ì •í•œ ë°©ì‹)
            if 'keypoints' in keypoint_input:
                final_keypoints = keypoint_input['keypoints']
                logger.info(f"ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì‹ : {len(final_keypoints)}ê°œ")
            
            # 2. ì—†ë‹¤ë©´ ì˜ˆì „ ë°©ì‹(body, face...)ìœ¼ë¡œ ì‹œë„
            else:
                body = keypoint_input.get('body') or []
                face = keypoint_input.get('face') or []
                left_hand = keypoint_input.get('leftHand') or []
                right_hand = keypoint_input.get('rightHand') or []
                final_keypoints = body + face + left_hand + right_hand
                logger.info(f"ë¶„í•  ë°ì´í„° ìˆ˜ì‹  ë° í•©ì²´ ì™„ë£Œ")
        
        elif isinstance(keypoint_input, list):
            final_keypoints = keypoint_input
        else:
            return jsonify({"error": "Unknown data format"}), 400

        # ë°ì´í„° ê°œìˆ˜ í™•ì¸ ë¡œê·¸
        if len(final_keypoints) == 0:
            logger.error("ì¶”ì¶œëœ í‚¤í¬ì¸íŠ¸ê°€ 0ê°œì…ë‹ˆë‹¤. (ë°ì´í„° ë§¤í•‘ ì‹¤íŒ¨)")
            return jsonify({"error": "Extracted keypoints are empty"}), 400

        # ì „ì²˜ë¦¬
        feature_vector = preprocess_frame(final_keypoints)
        
        if feature_vector is None:
            return jsonify({"error": "Preprocessing failed"}), 400
            
        # ì„ì‹œ ë²„í¼ ë° ì¶”ë¡ 
        temp_buffer = deque([feature_vector])
        
        result = execute_inference(
            frame_buffer=temp_buffer,
            service=SERVICE,
            validator=GLOBAL_VALIDATOR,
            session_id=session_id,
            required_frames=MAX_BUFFER_FRAMES
        )

        if result and "type" not in result:
            return jsonify(result)
        else:
            # ì‹¤íŒ¨í•´ë„ 200 OKë¡œ ë¹ˆ ê°’ ë°˜í™˜ (ìë°” ì—ëŸ¬ ë°©ì§€)
            return jsonify({"departureCity": "ì¸ì‹ ì¤‘...", "arrivalCity": None, "recognizedProb": 0.0}), 200

    except Exception as e:
        logger.error(f"HTTP ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500
# =============================================================================
# [ROUTE] WebSocket (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# =============================================================================
@sock.route('/ws/predict')
def websocket_predict(ws):
    # ê¸°ì¡´ ì›¹ì†Œì¼“ ë¡œì§ ìœ ì§€
    logger.info("ğŸ”— WebSocket í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨")
    frame_buffer = deque(maxlen=MAX_BUFFER_FRAMES)
    last_frame_index = -1
    session_id = "unknown"
    frames_since_last_inference = 0

    while True:
        try:
            message_str = ws.receive()
            if message_str is None: break
            
            message = json.loads(message_str)
            msg_type = message.get('type')

            if msg_type == 'START_SESSION':
                session_id = message.get('sessionId', 'unknown')
                frame_buffer.clear()
                ws.send(json.dumps({"status": "connected"}))

            elif msg_type == 'KEYPOINT_FRAME':
                keypoints_data = message.get('keypoints')
                feature_vector = preprocess_frame(keypoints_data)
                
                if feature_vector is not None:
                    frame_buffer.append(feature_vector)
                    frames_since_last_inference += 1

                    if len(frame_buffer) == MAX_BUFFER_FRAMES and \
                       frames_since_last_inference >= INFERENCE_STRIDE:
                        
                        result = execute_inference(
                            frame_buffer, SERVICE, GLOBAL_VALIDATOR, session_id, required_frames=MAX_BUFFER_FRAMES
                        )
                        if result: ws.send(json.dumps(result))
                        frames_since_last_inference = 0

        except Exception as e:
            logger.error(f"WS Error: {e}")
            break

if __name__ == '__main__':
    logger.info("ğŸš€ Flask ì•± ì‹¤í–‰ ì¤‘ (Port: 5001)...")
    # í¬íŠ¸ 5001 ìœ ì§€ (ìë°”ì™€ ë™ì¼í•˜ê²Œ)
    app.run(host='0.0.0.0', port=5001, debug=False)