import json
import time
import atexit
from collections import deque
from typing import Optional, Dict, Any, List

import numpy as np
import torch
from flask import Flask, request, jsonify
from flask_sock import Sock
from simple_websocket.errors import ConnectionClosed

# --- ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ ì„í¬íŠ¸ ---
from input_keypoint.advanced_validators import AdvancedHandValidator
from realtime.segmenter import OnlineSegmenter
from realtime.inference_logger import InferenceLogger  # [ì¶”ê°€] ë°ì´í„° ë¡œê±°
from realtime.inference_utils import (
    load_model_and_vocab,
    predict,
    normalize_keypoints_by_bodypart
)
from utils.logger import get_logger, setup_project_logging # [ì¶”ê°€] ë¡œê¹… ì„¤ì •
from utils.config import load_config, get_default_config_path
from utils.performance import performance_optimizer

# =============================================================================
# [SETUP] ë¡œê±° ë° ì„¤ì • ì´ˆê¸°í™”
# =============================================================================
# 1. ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” (í™”ë©´ ì¶œë ¥ + íŒŒì¼ ì €ì¥)
setup_project_logging({
    "level": "INFO",
    "log_file": "logs/server.log",
    "format": "[%(asctime)s] %(levelname)s [%(name)s] %(message)s"
})

logger = get_logger("kslt.server")

config_path = get_default_config_path()
config = load_config(config_path)

# =============================================================================
# [CONSTANTS] ìƒìˆ˜ ì •ì˜
# =============================================================================
KEYPOINT_SLICES = {
    'body': slice(0, 25),
    'face': slice(25, 95),
    'left_hand': slice(95, 116),
    'right_hand': slice(116, 137)
}
NOSE_INDEX = 0
INFERENCE_STRIDE = 5

# =============================================================================
# [FUNCTIONS] í•µì‹¬ ë¡œì§
# =============================================================================

def preprocess_frame(keypoints_data: List[List[float]]) -> Optional[np.ndarray]:
    """
    í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„°ë¥¼ ëª¨ë¸ ì…ë ¥ìš© 1D ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if not keypoints_data:
        return None

    try:
        keypoints_arr = np.array(keypoints_data, dtype=np.float32)

        # ë°ì´í„° í˜•ìƒ ë§ì¶”ê¸° (x, y) -> (x, y, 0) ì²˜ë¦¬ ë“±
        if keypoints_arr.shape[1] == 2:
             zeros = np.zeros((keypoints_arr.shape[0], 1), dtype=np.float32)
             keypoints_arr = np.hstack([keypoints_arr, zeros])

        normalized_keypoints = normalize_keypoints_by_bodypart(
            keypoints_arr, width=1.0, height=1.0
        )

        body_pts = normalized_keypoints[KEYPOINT_SLICES['body']]
        face_pts = normalized_keypoints[KEYPOINT_SLICES['face']]
        lh_pts = normalized_keypoints[KEYPOINT_SLICES['left_hand']]
        rh_pts = normalized_keypoints[KEYPOINT_SLICES['right_hand']]

        nose_pt = body_pts[NOSE_INDEX]
        if nose_pt[2] > 0.1 and not np.isnan(nose_pt[0]):
            body_pts[:, :2] -= nose_pt[:2]

        xy = np.concatenate([
            body_pts[:, :2],
            face_pts[:, :2],
            lh_pts[:, :2],
            rh_pts[:, :2]
        ], axis=0)

        presence_mask_list = []
        for part_name in ['body', 'face', 'left_hand', 'right_hand']:
            part_data = xy[KEYPOINT_SLICES[part_name]]
            has_part = not np.all(np.isnan(part_data))
            length = KEYPOINT_SLICES[part_name].stop - KEYPOINT_SLICES[part_name].start
            presence_mask_list.append(np.full((length, 1), 1.0 if has_part else 0.0))

        presence_mask = np.vstack(presence_mask_list).astype(np.float32)
        coord_mask = (~np.isnan(xy).any(axis=1)).astype(np.float32).reshape(-1, 1)
        mask = presence_mask * coord_mask

        xy = np.nan_to_num(xy, nan=0.0, posinf=0.0, neginf=0.0)
        xy *= mask

        return xy.reshape(-1)

    except Exception as e:
        logger.error(f"ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def execute_inference(
    frame_buffer: deque,
    service: Any,
    validator: AdvancedHandValidator,
    data_logger: InferenceLogger,  # [ì¶”ê°€] ë°ì´í„° ë¡œê±°
    vocab: Any,                    # [ì¶”ê°€] ë‹¨ì–´ ID ì¡°íšŒìš©
    session_id: str = "unknown",
    top_k: int = 3,
    required_frames: int = 128
) -> Optional[Dict[str, Any]]:
    """
    ë²„í¼ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³ , ìƒì„¸ ë¡œê·¸ ë° ë°ì´í„° ì €ì¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    # HTTP ìš”ì²­ ëŒ€ì‘: ë²„í¼ê°€ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ë³µì œí•´ì„œë¼ë„ ì±„ì›€ (Padding)
    buffer_len = len(frame_buffer)
    if buffer_len == 0:
        return None

    working_buffer = list(frame_buffer)

    # [Code 1ì˜ íŒ¨ë”© ë¡œì§ ìœ ì§€] HTTP ë‹¨ë°œì„± ìš”ì²­ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìˆ˜
    if buffer_len < required_frames:
        # logger.debug(f"[{session_id}] ë²„í¼ ë¶€ì¡±({buffer_len}/{required_frames}). íŒ¨ë”© ìˆ˜í–‰.")
        while len(working_buffer) < required_frames:
            working_buffer.append(working_buffer[-1])

    try:
        start_time = time.perf_counter()
        # required_frames ê°œìˆ˜ë§Œí¼ë§Œ ì˜ë¼ì„œ ì‚¬ìš©
        input_tensor = np.stack(working_buffer[:required_frames], axis=0)

        # 1. ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        keypoints_for_val = input_tensor.reshape(required_frames, 137, 2)
        val_res = validator.validate_sequence(keypoints_for_val, skip_head_occlusion=True)

        # í’ˆì§ˆ ì´ìŠˆê°€ ìˆì–´ë„ ì¼ë‹¨ ì¶”ë¡ ì€ ì§„í–‰í•˜ë˜, ë¡œê·¸ì— ë‚¨ê¹€
        if not val_res['is_valid']:
            pass # í•„ìš” ì‹œ debug ë¡œê·¸ ì¶”ê°€ ê°€ëŠ¥

        # 2. ëª¨ë¸ ì¶”ë¡ 
        result = service.predict(input_tensor, return_probabilities=True, top_k=top_k)
        elapsed = (time.perf_counter() - start_time) * 1000

        prediction = result['top_prediction']
        confidence = float(result['top_confidence'])

        # 3. [ìƒì„¸ ë¡œê¹…] Code 2 ìŠ¤íƒ€ì¼ ì ìš©
        status_tag = "âœ… Accepted" if confidence > 60.0 else "âš ï¸ Low Conf"

        # HTTP ìš”ì²­ì¸ ê²½ìš°ì™€ WSì¸ ê²½ìš° êµ¬ë¶„ì„ ìœ„í•´ ì„¸ì…˜ ID í™œìš©
        req_type = "HTTP" if session_id == "HTTP_REQ" else "WS"

        log_msg = (f"[{session_id}] {status_tag} | "
                   f"ì˜ˆì¸¡: '{prediction}' ({confidence:.1f}%) | "
                   f"ì‹œê°„: {elapsed:.1f}ms | í’ˆì§ˆ: {val_res['quality_score']:.2f}")
        logger.info(log_msg)

        # 4. [ë°ì´í„° ì €ì¥] InferenceLogger ì‚¬ìš©
        label_id = -1
        if hasattr(vocab, 'stoi'):
            label_id = vocab.stoi.get(prediction, -1)

        data_logger.add(label_id=label_id, word=prediction, feat_window=input_tensor)

        return {
            "sessionId": session_id,
            "departureCity": prediction,
            "arrivalCity": None,
            "recognizedProb": confidence
        }

    except Exception as e:
        logger.error(f"[{session_id}] ì¶”ë¡  ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return {"type": "ERROR", "message": str(e)}


# =============================================================================
# [SERVER INIT] Flask ë° ëª¨ë¸ ë¡œë“œ
# =============================================================================
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False
sock = Sock(app)

MODEL_PATH = "deployment/20251109-1439_Attention/20251109-1439.onnx"
VOCAB_PATH = "deployment/20251109-1439_Attention/vocabulary.txt"
MODEL_TYPE = "onnx"

logger.info("ğŸš€ ì„œë²„ ì‹œì‘: ëª¨ë¸ ë° ë¦¬ì†ŒìŠ¤ ë¡œë”© ì¤‘...")

try:
    SERVICE, VOCAB, DEVICE = load_model_and_vocab(MODEL_PATH, VOCAB_PATH, "auto", MODEL_TYPE)
    realtime_config = config.get_realtime_config()
    logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ (Device: {DEVICE}, Type: {MODEL_TYPE})")
except Exception as e:
    logger.critical(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ì„œë²„ë¥¼ ì¢…ë£Œí•´ì•¼ í•©ë‹ˆë‹¤. {e}", exc_info=True)
    SERVICE, VOCAB, DEVICE = None, None, None

MAX_BUFFER_FRAMES = realtime_config.get('window_size', 200) if MODEL_TYPE == "pytorch" else 128
logger.info(f"âš™ï¸ ì„¤ì • ì™„ë£Œ: Window Size={MAX_BUFFER_FRAMES}, Stride={INFERENCE_STRIDE}")

# --- [ì¶”ê°€] ë°ì´í„° ë¡œê±° ì„¤ì • ---
data_config = config.get_data_config()
DATA_LOGGER = InferenceLogger(
    win=MAX_BUFFER_FRAMES,
    save_dir=data_config.get('save_dir', "data"),   # data í´ë”ì— ì €ì¥
    prefix="server_inference",                      # íŒŒì¼ëª… ì ‘ë‘ì‚¬
    save_csv_summary=True,                          # CSV ìš”ì•½ë³¸ ì €ì¥
    save_windows_csv=False                          # ì „ì²´ í…ì„œ ì €ì¥ì€ ë” (ìš©ëŸ‰ ì ˆì•½)
)
# ì„œë²„ ì¢…ë£Œ ì‹œ(Ctrl+C) ìë™ìœ¼ë¡œ save() í˜¸ì¶œ
atexit.register(DATA_LOGGER.save)
logger.info("ğŸ’¾ ë°ì´í„° ë¡œê±° í™œì„±í™”ë¨ (ì¢…ë£Œ ì‹œ 'data/' ì €ì¥)")
# ----------------------------------------------

validator_config = realtime_config.get('validator', {})
GLOBAL_VALIDATOR = AdvancedHandValidator(
    head_occlusion_threshold=validator_config.get('head_occlusion_threshold', 0.8),
    min_hand_movement=validator_config.get('min_hand_movement', 0.01),
    max_frame_gap=validator_config.get('max_frame_gap', 10),
    min_valid_frames_ratio=validator_config.get('min_valid_frames_ratio', 0.3)
)

# =============================================================================
# [ROUTE] HTTP POST (ìë°” ë°±ì—”ë“œ ì—°ë™ìš©)
# =============================================================================
@app.route('/predict_keypoints', methods=['POST'])
def http_predict_keypoints():
    """
    ìë°” ë°±ì—”ë“œì—ì„œ ì˜¤ëŠ” ë°ì´í„°ë¥¼ êµ¬ì¡°ì— ë§ê²Œ ë³€í™˜í•˜ì—¬ ì¶”ë¡ í•©ë‹ˆë‹¤.
    """
    try:
        data = request.get_json()
        session_id = "HTTP_REQ"

        keypoint_input = data.get('keypointData')

        if not keypoint_input:
            return jsonify({"error": "No keypoint data provided"}), 400

        final_keypoints = []

        # ìë°” êµ¬ì¡° ì²˜ë¦¬: { "keypoints": [...] } ë˜ëŠ” { "body": ..., "face": ... }
        if isinstance(keypoint_input, dict):
            if 'keypoints' in keypoint_input:
                final_keypoints = keypoint_input['keypoints']
                # logger.info(f"ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì‹ : {len(final_keypoints)}ê°œ")
            else:
                body = keypoint_input.get('body') or []
                face = keypoint_input.get('face') or []
                left_hand = keypoint_input.get('leftHand') or []
                right_hand = keypoint_input.get('rightHand') or []
                final_keypoints = body + face + left_hand + right_hand
                # logger.info(f"ë¶„í•  ë°ì´í„° ìˆ˜ì‹  ë° í•©ì²´ ì™„ë£Œ")

        elif isinstance(keypoint_input, list):
            final_keypoints = keypoint_input
        else:
            return jsonify({"error": "Unknown data format"}), 400

        if len(final_keypoints) == 0:
            logger.error("ì¶”ì¶œëœ í‚¤í¬ì¸íŠ¸ê°€ 0ê°œì…ë‹ˆë‹¤. (ë°ì´í„° ë§¤í•‘ ì‹¤íŒ¨)")
            return jsonify({"error": "Extracted keypoints are empty"}), 400

        # ì „ì²˜ë¦¬
        feature_vector = preprocess_frame(final_keypoints)

        if feature_vector is None:
            return jsonify({"error": "Preprocessing failed"}), 400

        # ì„ì‹œ ë²„í¼ ë° ì¶”ë¡ 
        # HTTP ìš”ì²­ì€ ë³´í†µ ë‹¨ë°œì„±ì´ë¯€ë¡œ, ì´ 1ê°œì˜ í”„ë ˆì„ì„ ë²„í¼ì— ë„£ê³ 
        # execute_inference ë‚´ë¶€ì—ì„œ íŒ¨ë”©(ë³µì œ)í•˜ì—¬ 128ê°œë¡œ ë§Œë“­ë‹ˆë‹¤.
        temp_buffer = deque([feature_vector])

        result = execute_inference(
            frame_buffer=temp_buffer,
            service=SERVICE,
            validator=GLOBAL_VALIDATOR,
            data_logger=DATA_LOGGER,  # ë¡œê±° ì „ë‹¬
            vocab=VOCAB,              # ë‹¨ì–´ì¥ ì „ë‹¬
            session_id=session_id,
            required_frames=MAX_BUFFER_FRAMES
        )

        if result and "type" not in result:
            return jsonify(result)
        else:
            # ì‹¤íŒ¨í•´ë„ 200 OKë¡œ ë¹ˆ ê°’ ë°˜í™˜ (ìë°” ì—ëŸ¬ ë°©ì§€)
            return jsonify({"departureCity": "ì¸ì‹ ì¤‘...", "arrivalCity": None, "recognizedProb": 0.0}), 200

    except Exception as e:
        logger.error(f"HTTP ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500

# =============================================================================
# [ROUTE] WebSocket
# =============================================================================
@sock.route('/ws/predict')
def websocket_predict(ws):
    logger.info("ğŸ”— ìƒˆë¡œìš´ WebSocket í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨")
    frame_buffer = deque(maxlen=MAX_BUFFER_FRAMES)
    last_frame_index = -1
    session_id = "unknown"
    frames_since_last_inference = 0

    while True:
        try:
            try:
                message_str = ws.receive()
            except ConnectionClosed:
                logger.info(f"[{session_id}] í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ì„ ì •ìƒ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤. (Code 1000)")
                break

            if message_str is None:
                logger.info(f"[{session_id}] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ (EOF)")
                break

            try:
                message = json.loads(message_str)
            except json.JSONDecodeError:
                logger.warning(f"[{session_id}] ì˜ëª»ëœ JSON í˜•ì‹ ìˆ˜ì‹ ")
                continue

            msg_type = message.get('type')

            if msg_type == 'START_SESSION':
                session_id = message.get('sessionId', 'unknown')
                logger.info(f"âœ¨ ì„¸ì…˜ ì‹œì‘ [{session_id}] - ë²„í¼ ì´ˆê¸°í™”ë¨")
                frame_buffer.clear()
                frames_since_last_inference = 0
                ws.send(json.dumps({"status": "connected", "sessionId": session_id}))

            elif msg_type == 'KEYPOINT_FRAME':
                # í´ë¼ì´ì–¸íŠ¸ ì¬ì‹œì‘ ê°ì§€ (í”„ë ˆì„ ì¸ë±ìŠ¤ê°€ ë’¤ë¡œ ê°”ì„ ë•Œ)
                current_index = message.get('frameIndex', -1)
                if current_index >= 0 and current_index < last_frame_index:
                     logger.info(f"[{session_id}] ğŸ”„ í´ë¼ì´ì–¸íŠ¸ ì¬ì‹œì‘ ê°ì§€")
                     frame_buffer.clear()
                     frames_since_last_inference = 0
                last_frame_index = current_index

                keypoints_data = message.get('keypoints')
                feature_vector = preprocess_frame(keypoints_data)

                if feature_vector is not None:
                    frame_buffer.append(feature_vector)
                    frames_since_last_inference += 1

                    if len(frame_buffer) == MAX_BUFFER_FRAMES and \
                       frames_since_last_inference >= INFERENCE_STRIDE:

                        result = execute_inference(
                            frame_buffer=frame_buffer,
                            service=SERVICE,
                            validator=GLOBAL_VALIDATOR,
                            data_logger=DATA_LOGGER,  # ë¡œê±° ì „ë‹¬
                            vocab=VOCAB,              # ë‹¨ì–´ì¥ ì „ë‹¬
                            session_id=session_id,
                            required_frames=MAX_BUFFER_FRAMES
                        )

                        if result:
                            if "type" in result and result["type"] == "ERROR":
                                logger.error(f"[{session_id}] ì¶”ë¡  ì—ëŸ¬: {result['message']}")
                            else:
                                ws.send(json.dumps(result))

                        frames_since_last_inference = 0

        except Exception as e:
            logger.error(f"WS Error: {e}")
            break

    logger.info(f"ğŸ‘‹ ì—°ê²° ì™„ì „ ì¢…ë£Œ: {session_id}")

if __name__ == '__main__':
    logger.info("ğŸš€ Flask ì•± ì‹¤í–‰ ì¤‘ (Port: 5001)...")
    app.run(host='0.0.0.0', port=5001, debug=False)